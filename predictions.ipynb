{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1500 images belonging to 10 classes.\n",
      "Found 1000 images belonging to 10 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:60: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:60: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., epochs=5, validation_data=<keras.pre..., steps_per_epoch=150, validation_steps=100)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "149/150 [============================>.] - ETA: 0s - loss: 2.4421 - acc: 0.3208"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import GlobalAveragePooling2D, Flatten, Dense, Input, Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "path = '/home/ubuntu/nbs/state_farm/data/sample/'\n",
    "batch_size=10\n",
    "\n",
    "#path = '/home/ubuntu/nbs/state_farm/data/'\n",
    "#batch_size=64\n",
    "\n",
    "target_size=(224, 224)\n",
    "\n",
    "\n",
    "#generate the batches\n",
    "def get_batches(directory, target_size=target_size, batch_size=batch_size, shuffle=False):\n",
    "    datagen = ImageDataGenerator()\n",
    "    return datagen.flow_from_directory(directory=directory,\n",
    "                                          target_size=target_size,\n",
    "                                          batch_size=batch_size,\n",
    "                                          class_mode='categorical',\n",
    "                                          shuffle=shuffle)\n",
    "\n",
    "train_gen = ImageDataGenerator(rotation_range=0, \n",
    "                                     width_shift_range=0, \n",
    "                                     height_shift_range=0.1, \n",
    "                                     shear_range=0.1, \n",
    "                                     zoom_range=0.2, \n",
    "                                     channel_shift_range=10,\n",
    "                                     fill_mode='nearest')\n",
    "\n",
    "batches = train_gen.flow_from_directory(directory=path+'train_set',  \n",
    "                                        target_size=target_size,\n",
    "                                        batch_size=batch_size,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=True)\n",
    "\n",
    "#batches = get_batches(path+'train_set', shuffle=True)\n",
    "\n",
    "valid_batches = get_batches(path+'valid_set', batch_size=batch_size*2, shuffle=False)\n",
    "\n",
    "# initialize the model\n",
    "initial_model = VGG16(weights=\"imagenet\", include_top=True)\n",
    "\n",
    "#finetuning\n",
    "x = Dense(batches.num_class, activation='softmax')(initial_model.layers[-2].output)\n",
    "model = Model(initial_model.input, x)\n",
    "\n",
    "# we freeze the other layers \n",
    "for layer in initial_model.layers: layer.trainable=False\n",
    "\n",
    "opt = Adam(lr=0.001)\n",
    "model.compile(optimizer=opt,\n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit_generator(batches, steps_per_epoch=batches.samples//batch_size, nb_epoch=5,\n",
    "                validation_data=valid_batches, validation_steps=valid_batches.samples//batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:10]: \n",
    "    layer.trainable = False \n",
    "\n",
    "for layer in model.layers[10:]: \n",
    "    layer.trainable = True\n",
    "    \n",
    "opt = SGD(lr=10e-5) \n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(batches, steps_per_epoch=batches.samples//batch_size, \n",
    "                    nb_epoch=10, validation_data=valid_batches, \n",
    "                    validation_steps=valid_batches.samples//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predictions on new data\n",
    "test_batches = get_batches(path+'test', batch_size=batch_size)\n",
    "preds = model.predict_generator(test_batches, steps=test_batches.samples//batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds_clipes = preds.clip(min=0.01, max=0.99)\n",
    "print(preds_clipes[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
